{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convertPDFtoTXT import PDFtoTextVar\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial Optimisations Report Introduction to High Performance Computing (COMS30005)  Oliver Ryan-George (or16131) 26/10/2018  Introduction  This report is a discussion of the optimisation of the function stencil in the given program stencil.c. I will begin by presenting the speeds of the fastest optimisation and then continue by explaining how diﬀerent optimisations aﬀect the speed and why. I will then ﬁnish by reﬂecting on how fast the ﬁnal program could have been and what could be done to further optimise it.  Results  The results for the ﬁnal program submitted on SAFE were taken as an average of ﬁve runs and are presented below in Table 1. The eﬀects of diﬀerent alterations to the ﬁnal code are shown in Figure 1 and are referenced throughout.  Image Size 1024x1024 4096x4096 8000x8000  Table 1: Results  Initial runtime (s) Final runtime (s)  8.153425 313.894160 611.285008  0.088110 2.463002 8.371530  1 Vectorisation  The most impactful changes on the eﬃciency of the function involved optimising it for vectorisation. Vectorisation is where the compiler parallelises code by performing an operation, lying within a for loop, on a vector containing several elements of a subject array simultaneously. This is as opposed to performing the operation on sequentially on each element of the array.  In order for the compiler to vectorise code eﬀectively, for loops and data accesses need to take a certain form. One important rule is to make sure that array elements are accessed incrementally according to their index. This is so the compiler can put elements positioned next to each other in memory in vectors. This was not the case in the original code as the variable i was on the inside of a nested loop which was being multiplied in the index of arrays. By changing the loops in the ﬁnal program we see a decrease in the time taken by a factor of 11 for an 8000x8000 image.  Another rule is to make sure it is clear to the compiler that there will be no pointer aliasing in the program using the restrict keyword. Without it, the vectorisation report states that there is an assumed dependence between arrays. Putting restrict in sees a decrease in the time taken by a factor of 5 for an 8000x8000 image.  A third rule is to make sure operations are separated to make it simple for the compiler to perform them. This is a compromise since I initially hypothesised that it would be faster to do all the operations at once so the subject array element would only have to be loaded and stored once. This ended up mattering little, probably since the cost of going to a low-level cache is very small. It would also have the beneﬁt of allowing factorisation so less costly multiplication would need to be done. The beneﬁts of vectorisation outweigh this, however, as the vectorised version is marginally faster.  2 Data types  The choice of data type has a signiﬁcant impact on the eﬃciency of the program. The original code used doubles, each consisting of eight bytes which is unnecessarily precise for the task being performed. Floats consist of four bytes each and are suﬃcient to pass the test. Changing from doubles to ﬂoats doubles the operational intensity of the function which is especially beneﬁcial as the program is memory bandwidth bound so we want to minimise the number of bytes loaded and stored per operation. Doing this approximately halves the time taken to run the function for all image sizes.  1  \f",
      "The ﬂoating point operation, division, takes far more clock cycles to compute than multiplication because the Intel compiler used divides by ﬁrst ﬁnding the reciprocal of the denominator and then multiplying it. This is why replacing all division operations with multiplication reduces the time taken to run the function by a factor of 20.  3 Storing variables  Aware that memory bandwidth is often the bottleneck for programs, I originally approached the task with the attitude that no variables should be stored and all repeated values should be recomputed. After some trial and error, this was the slowest approach. Recomputing multiplications turned out to be slightly slower than retrieving data from a low-level cache. It was fastest, albeit only just, to take a mixed approach with values that were computed with multiplication and that were used several times stored as variables with simple, less used, values recalculated every time.  4 Compilers  My ﬁnal program is compiled using the command: ”icc -O3 -xHOST -std=c99 -Wall stencil.c -o stencil”. I chose to use the icc compiler because of its automatic vectorisation which enabled all the speed increases mentioned in the ﬁrst section. As can be seen below in Graph 1c, the gcc compiler performs similarly to using the icc compiler with the -O1 ﬂag. This is because vectorisation is disabled with the -O1 ﬂag. The -O3 ﬂag performs best because it is designed for loop-heavy programs that operate on large datasets. xHost marginally increases the eﬃciency of the program by telling the compiler to generate the highest level instruction set available on the compilation host processor.  Vectorised Factorised  Loops switched ’restrict’ removed  50  40  30  20  10  0  t  0  2,000  4,000 n  6,000  8,000  (a) Eﬃciency using varying levels of vectorisation  Evaluation  150  100  t  50  0  0  Floats Doubles Division  -O3 -O2 -O1  Without xHost  gcc compiler  t  25  20  15  10  5  0  2,000  4,000  6,000  8,000  0  2,000  4,000  6,000  8,000  n  n  t  8.6  8.55  8.5  8.45  8.4  8.35  Mixed  No variables All variables  7,8607,8807,9007,9207,9407,9607,9808,000  n  (b) Eﬃciency of diﬀerent data types  (c) Eﬃciency of diﬀerent compilers  (d) Eﬃciency of using vari- ables against recomputing  Figure 1: Results of diﬀerent optimisations  Analysing for an 8000x8000 image, I found that the program performed 1.162GF LOP S in 8.372s. This gives it a performance of 0.139GF LOP S/s. Meanwhile, with 3.10 × 109bytes read and written, this gives an operational intensity of 0.374F LOP S/byte This puts the model some way oﬀ the roof of Blue Crystal’s peak DRAM bandwidth. The function would have to be 32 times faster at that operational intensity to hit Blue Crystal’s peak DRAM bandwidth.  This raises the question of how could the program be made faster to reach that peak performance. A proﬁler shows that 85% of time spent in the program is within the inner loop. Therefore, it would be most appropriate to look to make improvements here. Since it is a loop, it would be best to optimise further for vectorisation, possibly using techniques such as data alignment. It can also be seen from vectorisation reports that the other two loops do not vectorise because of supposed data dependencies but this is less pressing because there are far fewer iterations of these loops so not much time is spent on them.  2  \f",
      "\n"
     ]
    }
   ],
   "source": [
    "text = PDFtoTextVar('example.pdf')\n",
    "textwopars = text.replace('\\n', ' ')\n",
    "print(textwopars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial Optimisations Report Introduction to High Performance Computing COMS30005  Oliver RyanGeorge or16131 26102018  Introduction  This report is a discussion of the optimisation of the function stencil in the given program stencilc I will begin by presenting the speeds of the fastest optimisation and then continue by explaining how diﬀerent optimisations aﬀect the speed and why I will then ﬁnish by reﬂecting on how fast the ﬁnal program could have been and what could be done to further optimise it  Results  The results for the ﬁnal program submitted on SAFE were taken as an average of ﬁve runs and are presented below in Table 1 The eﬀects of diﬀerent alterations to the ﬁnal code are shown in Figure 1 and are referenced throughout  Image Size 1024x1024 4096x4096 8000x8000  Table 1 Results  Initial runtime s Final runtime s  8153425 313894160 611285008  0088110 2463002 8371530  1 Vectorisation  The most impactful changes on the eﬃciency of the function involved optimising it for vectorisation Vectorisation is where the compiler parallelises code by performing an operation lying within a for loop on a vector containing several elements of a subject array simultaneously This is as opposed to performing the operation on sequentially on each element of the array  In order for the compiler to vectorise code eﬀectively for loops and data accesses need to take a certain form One important rule is to make sure that array elements are accessed incrementally according to their index This is so the compiler can put elements positioned next to each other in memory in vectors This was not the case in the original code as the variable i was on the inside of a nested loop which was being multiplied in the index of arrays By changing the loops in the ﬁnal program we see a decrease in the time taken by a factor of 11 for an 8000x8000 image  Another rule is to make sure it is clear to the compiler that there will be no pointer aliasing in the program using the restrict keyword Without it the vectorisation report states that there is an assumed dependence between arrays Putting restrict in sees a decrease in the time taken by a factor of 5 for an 8000x8000 image  A third rule is to make sure operations are separated to make it simple for the compiler to perform them This is a compromise since I initially hypothesised that it would be faster to do all the operations at once so the subject array element would only have to be loaded and stored once This ended up mattering little probably since the cost of going to a lowlevel cache is very small It would also have the beneﬁt of allowing factorisation so less costly multiplication would need to be done The beneﬁts of vectorisation outweigh this however as the vectorised version is marginally faster  2 Data types  The choice of data type has a signiﬁcant impact on the eﬃciency of the program The original code used doubles each consisting of eight bytes which is unnecessarily precise for the task being performed Floats consist of four bytes each and are suﬃcient to pass the test Changing from doubles to ﬂoats doubles the operational intensity of the function which is especially beneﬁcial as the program is memory bandwidth bound so we want to minimise the number of bytes loaded and stored per operation Doing this approximately halves the time taken to run the function for all image sizes  1  \f",
      "The ﬂoating point operation division takes far more clock cycles to compute than multiplication because the Intel compiler used divides by ﬁrst ﬁnding the reciprocal of the denominator and then multiplying it This is why replacing all division operations with multiplication reduces the time taken to run the function by a factor of 20  3 Storing variables  Aware that memory bandwidth is often the bottleneck for programs I originally approached the task with the attitude that no variables should be stored and all repeated values should be recomputed After some trial and error this was the slowest approach Recomputing multiplications turned out to be slightly slower than retrieving data from a lowlevel cache It was fastest albeit only just to take a mixed approach with values that were computed with multiplication and that were used several times stored as variables with simple less used values recalculated every time  4 Compilers  My ﬁnal program is compiled using the command ”icc O3 xHOST stdc99 Wall stencilc o stencil” I chose to use the icc compiler because of its automatic vectorisation which enabled all the speed increases mentioned in the ﬁrst section As can be seen below in Graph 1c the gcc compiler performs similarly to using the icc compiler with the O1 ﬂag This is because vectorisation is disabled with the O1 ﬂag The O3 ﬂag performs best because it is designed for loopheavy programs that operate on large datasets xHost marginally increases the eﬃciency of the program by telling the compiler to generate the highest level instruction set available on the compilation host processor  Vectorised Factorised  Loops switched ’restrict’ removed  50  40  30  20  10  0  t  0  2000  4000 n  6000  8000  a Eﬃciency using varying levels of vectorisation  Evaluation  150  100  t  50  0  0  Floats Doubles Division  O3 O2 O1  Without xHost  gcc compiler  t  25  20  15  10  5  0  2000  4000  6000  8000  0  2000  4000  6000  8000  n  n  t  86  855  85  845  84  835  Mixed  No variables All variables  78607880790079207940796079808000  n  b Eﬃciency of diﬀerent data types  c Eﬃciency of diﬀerent compilers  d Eﬃciency of using vari ables against recomputing  Figure 1 Results of diﬀerent optimisations  Analysing for an 8000x8000 image I found that the program performed 1162GF LOP S in 8372s This gives it a performance of 0139GF LOP Ss Meanwhile with 310 × 109bytes read and written this gives an operational intensity of 0374F LOP Sbyte This puts the model some way oﬀ the roof of Blue Crystal’s peak DRAM bandwidth The function would have to be 32 times faster at that operational intensity to hit Blue Crystal’s peak DRAM bandwidth  This raises the question of how could the program be made faster to reach that peak performance A proﬁler shows that 85 of time spent in the program is within the inner loop Therefore it would be most appropriate to look to make improvements here Since it is a loop it would be best to optimise further for vectorisation possibly using techniques such as data alignment It can also be seen from vectorisation reports that the other two loops do not vectorise because of supposed data dependencies but this is less pressing because there are far fewer iterations of these loops so not much time is spent on them  2  \f",
      "\n"
     ]
    }
   ],
   "source": [
    "remove_punct_map = dict.fromkeys(map(ord, string.punctuation))\n",
    "textwopunctuation = textwopars.translate(remove_punct_map)\n",
    "print(textwopunctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Serial', 'Optimisations', 'Report', 'Introduction', 'to', 'High', 'Performance', 'Computing', 'COMS30005', '', 'Oliver', 'RyanGeorge', 'or16131', '26102018', '', 'Introduction', '', 'This', 'report', 'is', 'a', 'discussion', 'of', 'the', 'optimisation', 'of', 'the', 'function', 'stencil', 'in', 'the', 'given', 'program', 'stencilc', 'I', 'will', 'begin', 'by', 'presenting', 'the', 'speeds', 'of', 'the', 'fastest', 'optimisation', 'and', 'then', 'continue', 'by', 'explaining', 'how', 'diﬀerent', 'optimisations', 'aﬀect', 'the', 'speed', 'and', 'why', 'I', 'will', 'then', 'ﬁnish', 'by', 'reﬂecting', 'on', 'how', 'fast', 'the', 'ﬁnal', 'program', 'could', 'have', 'been', 'and', 'what', 'could', 'be', 'done', 'to', 'further', 'optimise', 'it', '', 'Results', '', 'The', 'results', 'for', 'the', 'ﬁnal', 'program', 'submitted', 'on', 'SAFE', 'were', 'taken', 'as', 'an', 'average', 'of', 'ﬁve', 'runs', 'and', 'are', 'presented', 'below', 'in', 'Table', '1', 'The', 'eﬀects', 'of', 'diﬀerent', 'alterations', 'to', 'the', 'ﬁnal', 'code', 'are', 'shown', 'in', 'Figure', '1', 'and', 'are', 'referenced', 'throughout', '', 'Image', 'Size', '1024x1024', '4096x4096', '8000x8000', '', 'Table', '1', 'Results', '', 'Initial', 'runtime', 's', 'Final', 'runtime', 's', '', '8153425', '313894160', '611285008', '', '0088110', '2463002', '8371530', '', '1', 'Vectorisation', '', 'The', 'most', 'impactful', 'changes', 'on', 'the', 'eﬃciency', 'of', 'the', 'function', 'involved', 'optimising', 'it', 'for', 'vectorisation', 'Vectorisation', 'is', 'where', 'the', 'compiler', 'parallelises', 'code', 'by', 'performing', 'an', 'operation', 'lying', 'within', 'a', 'for', 'loop', 'on', 'a', 'vector', 'containing', 'several', 'elements', 'of', 'a', 'subject', 'array', 'simultaneously', 'This', 'is', 'as', 'opposed', 'to', 'performing', 'the', 'operation', 'on', 'sequentially', 'on', 'each', 'element', 'of', 'the', 'array', '', 'In', 'order', 'for', 'the', 'compiler', 'to', 'vectorise', 'code', 'eﬀectively', 'for', 'loops', 'and', 'data', 'accesses', 'need', 'to', 'take', 'a', 'certain', 'form', 'One', 'important', 'rule', 'is', 'to', 'make', 'sure', 'that', 'array', 'elements', 'are', 'accessed', 'incrementally', 'according', 'to', 'their', 'index', 'This', 'is', 'so', 'the', 'compiler', 'can', 'put', 'elements', 'positioned', 'next', 'to', 'each', 'other', 'in', 'memory', 'in', 'vectors', 'This', 'was', 'not', 'the', 'case', 'in', 'the', 'original', 'code', 'as', 'the', 'variable', 'i', 'was', 'on', 'the', 'inside', 'of', 'a', 'nested', 'loop', 'which', 'was', 'being', 'multiplied', 'in', 'the', 'index', 'of', 'arrays', 'By', 'changing', 'the', 'loops', 'in', 'the', 'ﬁnal', 'program', 'we', 'see', 'a', 'decrease', 'in', 'the', 'time', 'taken', 'by', 'a', 'factor', 'of', '11', 'for', 'an', '8000x8000', 'image', '', 'Another', 'rule', 'is', 'to', 'make', 'sure', 'it', 'is', 'clear', 'to', 'the', 'compiler', 'that', 'there', 'will', 'be', 'no', 'pointer', 'aliasing', 'in', 'the', 'program', 'using', 'the', 'restrict', 'keyword', 'Without', 'it', 'the', 'vectorisation', 'report', 'states', 'that', 'there', 'is', 'an', 'assumed', 'dependence', 'between', 'arrays', 'Putting', 'restrict', 'in', 'sees', 'a', 'decrease', 'in', 'the', 'time', 'taken', 'by', 'a', 'factor', 'of', '5', 'for', 'an', '8000x8000', 'image', '', 'A', 'third', 'rule', 'is', 'to', 'make', 'sure', 'operations', 'are', 'separated', 'to', 'make', 'it', 'simple', 'for', 'the', 'compiler', 'to', 'perform', 'them', 'This', 'is', 'a', 'compromise', 'since', 'I', 'initially', 'hypothesised', 'that', 'it', 'would', 'be', 'faster', 'to', 'do', 'all', 'the', 'operations', 'at', 'once', 'so', 'the', 'subject', 'array', 'element', 'would', 'only', 'have', 'to', 'be', 'loaded', 'and', 'stored', 'once', 'This', 'ended', 'up', 'mattering', 'little', 'probably', 'since', 'the', 'cost', 'of', 'going', 'to', 'a', 'lowlevel', 'cache', 'is', 'very', 'small', 'It', 'would', 'also', 'have', 'the', 'beneﬁt', 'of', 'allowing', 'factorisation', 'so', 'less', 'costly', 'multiplication', 'would', 'need', 'to', 'be', 'done', 'The', 'beneﬁts', 'of', 'vectorisation', 'outweigh', 'this', 'however', 'as', 'the', 'vectorised', 'version', 'is', 'marginally', 'faster', '', '2', 'Data', 'types', '', 'The', 'choice', 'of', 'data', 'type', 'has', 'a', 'signiﬁcant', 'impact', 'on', 'the', 'eﬃciency', 'of', 'the', 'program', 'The', 'original', 'code', 'used', 'doubles', 'each', 'consisting', 'of', 'eight', 'bytes', 'which', 'is', 'unnecessarily', 'precise', 'for', 'the', 'task', 'being', 'performed', 'Floats', 'consist', 'of', 'four', 'bytes', 'each', 'and', 'are', 'suﬃcient', 'to', 'pass', 'the', 'test', 'Changing', 'from', 'doubles', 'to', 'ﬂoats', 'doubles', 'the', 'operational', 'intensity', 'of', 'the', 'function', 'which', 'is', 'especially', 'beneﬁcial', 'as', 'the', 'program', 'is', 'memory', 'bandwidth', 'bound', 'so', 'we', 'want', 'to', 'minimise', 'the', 'number', 'of', 'bytes', 'loaded', 'and', 'stored', 'per', 'operation', 'Doing', 'this', 'approximately', 'halves', 'the', 'time', 'taken', 'to', 'run', 'the', 'function', 'for', 'all', 'image', 'sizes', '', '1', '', '\\x0cThe', 'ﬂoating', 'point', 'operation', 'division', 'takes', 'far', 'more', 'clock', 'cycles', 'to', 'compute', 'than', 'multiplication', 'because', 'the', 'Intel', 'compiler', 'used', 'divides', 'by', 'ﬁrst', 'ﬁnding', 'the', 'reciprocal', 'of', 'the', 'denominator', 'and', 'then', 'multiplying', 'it', 'This', 'is', 'why', 'replacing', 'all', 'division', 'operations', 'with', 'multiplication', 'reduces', 'the', 'time', 'taken', 'to', 'run', 'the', 'function', 'by', 'a', 'factor', 'of', '20', '', '3', 'Storing', 'variables', '', 'Aware', 'that', 'memory', 'bandwidth', 'is', 'often', 'the', 'bottleneck', 'for', 'programs', 'I', 'originally', 'approached', 'the', 'task', 'with', 'the', 'attitude', 'that', 'no', 'variables', 'should', 'be', 'stored', 'and', 'all', 'repeated', 'values', 'should', 'be', 'recomputed', 'After', 'some', 'trial', 'and', 'error', 'this', 'was', 'the', 'slowest', 'approach', 'Recomputing', 'multiplications', 'turned', 'out', 'to', 'be', 'slightly', 'slower', 'than', 'retrieving', 'data', 'from', 'a', 'lowlevel', 'cache', 'It', 'was', 'fastest', 'albeit', 'only', 'just', 'to', 'take', 'a', 'mixed', 'approach', 'with', 'values', 'that', 'were', 'computed', 'with', 'multiplication', 'and', 'that', 'were', 'used', 'several', 'times', 'stored', 'as', 'variables', 'with', 'simple', 'less', 'used', 'values', 'recalculated', 'every', 'time', '', '4', 'Compilers', '', 'My', 'ﬁnal', 'program', 'is', 'compiled', 'using', 'the', 'command', '”icc', 'O3', 'xHOST', 'stdc99', 'Wall', 'stencilc', 'o', 'stencil”', 'I', 'chose', 'to', 'use', 'the', 'icc', 'compiler', 'because', 'of', 'its', 'automatic', 'vectorisation', 'which', 'enabled', 'all', 'the', 'speed', 'increases', 'mentioned', 'in', 'the', 'ﬁrst', 'section', 'As', 'can', 'be', 'seen', 'below', 'in', 'Graph', '1c', 'the', 'gcc', 'compiler', 'performs', 'similarly', 'to', 'using', 'the', 'icc', 'compiler', 'with', 'the', 'O1', 'ﬂag', 'This', 'is', 'because', 'vectorisation', 'is', 'disabled', 'with', 'the', 'O1', 'ﬂag', 'The', 'O3', 'ﬂag', 'performs', 'best', 'because', 'it', 'is', 'designed', 'for', 'loopheavy', 'programs', 'that', 'operate', 'on', 'large', 'datasets', 'xHost', 'marginally', 'increases', 'the', 'eﬃciency', 'of', 'the', 'program', 'by', 'telling', 'the', 'compiler', 'to', 'generate', 'the', 'highest', 'level', 'instruction', 'set', 'available', 'on', 'the', 'compilation', 'host', 'processor', '', 'Vectorised', 'Factorised', '', 'Loops', 'switched', '’restrict’', 'removed', '', '50', '', '40', '', '30', '', '20', '', '10', '', '0', '', 't', '', '0', '', '2000', '', '4000', 'n', '', '6000', '', '8000', '', 'a', 'Eﬃciency', 'using', 'varying', 'levels', 'of', 'vectorisation', '', 'Evaluation', '', '150', '', '100', '', 't', '', '50', '', '0', '', '0', '', 'Floats', 'Doubles', 'Division', '', 'O3', 'O2', 'O1', '', 'Without', 'xHost', '', 'gcc', 'compiler', '', 't', '', '25', '', '20', '', '15', '', '10', '', '5', '', '0', '', '2000', '', '4000', '', '6000', '', '8000', '', '0', '', '2000', '', '4000', '', '6000', '', '8000', '', 'n', '', 'n', '', 't', '', '86', '', '855', '', '85', '', '845', '', '84', '', '835', '', 'Mixed', '', 'No', 'variables', 'All', 'variables', '', '78607880790079207940796079808000', '', 'n', '', 'b', 'Eﬃciency', 'of', 'diﬀerent', 'data', 'types', '', 'c', 'Eﬃciency', 'of', 'diﬀerent', 'compilers', '', 'd', 'Eﬃciency', 'of', 'using', 'vari', 'ables', 'against', 'recomputing', '', 'Figure', '1', 'Results', 'of', 'diﬀerent', 'optimisations', '', 'Analysing', 'for', 'an', '8000x8000', 'image', 'I', 'found', 'that', 'the', 'program', 'performed', '1162GF', 'LOP', 'S', 'in', '8372s', 'This', 'gives', 'it', 'a', 'performance', 'of', '0139GF', 'LOP', 'Ss', 'Meanwhile', 'with', '310', '×', '109bytes', 'read', 'and', 'written', 'this', 'gives', 'an', 'operational', 'intensity', 'of', '0374F', 'LOP', 'Sbyte', 'This', 'puts', 'the', 'model', 'some', 'way', 'oﬀ', 'the', 'roof', 'of', 'Blue', 'Crystal’s', 'peak', 'DRAM', 'bandwidth', 'The', 'function', 'would', 'have', 'to', 'be', '32', 'times', 'faster', 'at', 'that', 'operational', 'intensity', 'to', 'hit', 'Blue', 'Crystal’s', 'peak', 'DRAM', 'bandwidth', '', 'This', 'raises', 'the', 'question', 'of', 'how', 'could', 'the', 'program', 'be', 'made', 'faster', 'to', 'reach', 'that', 'peak', 'performance', 'A', 'proﬁler', 'shows', 'that', '85', 'of', 'time', 'spent', 'in', 'the', 'program', 'is', 'within', 'the', 'inner', 'loop', 'Therefore', 'it', 'would', 'be', 'most', 'appropriate', 'to', 'look', 'to', 'make', 'improvements', 'here', 'Since', 'it', 'is', 'a', 'loop', 'it', 'would', 'be', 'best', 'to', 'optimise', 'further', 'for', 'vectorisation', 'possibly', 'using', 'techniques', 'such', 'as', 'data', 'alignment', 'It', 'can', 'also', 'be', 'seen', 'from', 'vectorisation', 'reports', 'that', 'the', 'other', 'two', 'loops', 'do', 'not', 'vectorise', 'because', 'of', 'supposed', 'data', 'dependencies', 'but', 'this', 'is', 'less', 'pressing', 'because', 'there', 'are', 'far', 'fewer', 'iterations', 'of', 'these', 'loops', 'so', 'not', 'much', 'time', 'is', 'spent', 'on', 'them', '', '2', '', '\\x0c']\n"
     ]
    }
   ],
   "source": [
    "words = textwopunctuation.split(' ')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Serial Optimisations Report\\nIntroduction to High Performance Computing (COMS30005)\\n\\nOliver Ryan-George (or16131)\\n26/10/2018\\n\\nIntroduction\\n\\nThis report is a discussion of the optimisation of the function stencil in the given program stencil', 'c', '\\nI will begin by presenting the speeds of the fastest optimisation and then continue by explaining how\\ndiﬀerent optimisations aﬀect the speed and why', ' I will then ﬁnish by reﬂecting on how fast the ﬁnal\\nprogram could have been and what could be done to further optimise it', '\\n\\nResults\\n\\nThe results for the ﬁnal program submitted on SAFE were taken as an average of ﬁve runs and are\\npresented below in Table 1', ' The eﬀects of diﬀerent alterations to the ﬁnal code are shown in Figure 1\\nand are referenced throughout', '\\n\\nImage Size\\n1024x1024\\n4096x4096\\n8000x8000\\n\\nTable 1: Results\\n\\nInitial runtime (s) Final runtime (s)\\n\\n8', '153425\\n313', '894160\\n611', '285008\\n\\n0', '088110\\n2', '463002\\n8', '371530\\n\\n1 Vectorisation\\n\\nThe most impactful changes on the eﬃciency of the function involved optimising it for vectorisation', '\\nVectorisation is where the compiler parallelises code by performing an operation, lying within a for\\nloop, on a vector containing several elements of a subject array simultaneously', ' This is as opposed to\\nperforming the operation on sequentially on each element of the array', '\\n\\nIn order for the compiler to vectorise code eﬀectively, for loops and data accesses need to take\\na certain form', ' One important rule is to make sure that array elements are accessed incrementally\\naccording to their index', ' This is so the compiler can put elements positioned next to each other in\\nmemory in vectors', ' This was not the case in the original code as the variable i was on the inside of\\na nested loop which was being multiplied in the index of arrays', ' By changing the loops in the ﬁnal\\nprogram we see a decrease in the time taken by a factor of 11 for an 8000x8000 image', '\\n\\nAnother rule is to make sure it is clear to the compiler that there will be no pointer aliasing in\\nthe program using the restrict keyword', ' Without it, the vectorisation report states that there is an\\nassumed dependence between arrays', ' Putting restrict in sees a decrease in the time taken by a factor\\nof 5 for an 8000x8000 image', '\\n\\nA third rule is to make sure operations are separated to make it simple for the compiler to perform\\nthem', ' This is a compromise since I initially hypothesised that it would be faster to do all the operations\\nat once so the subject array element would only have to be loaded and stored once', ' This ended up\\nmattering little, probably since the cost of going to a low-level cache is very small', ' It would also have\\nthe beneﬁt of allowing factorisation so less costly multiplication would need to be done', ' The beneﬁts\\nof vectorisation outweigh this, however, as the vectorised version is marginally faster', '\\n\\n2 Data types\\n\\nThe choice of data type has a signiﬁcant impact on the eﬃciency of the program', ' The original code\\nused doubles, each consisting of eight bytes which is unnecessarily precise for the task being performed', '\\nFloats consist of four bytes each and are suﬃcient to pass the test', ' Changing from doubles to ﬂoats\\ndoubles the operational intensity of the function which is especially beneﬁcial as the program is memory\\nbandwidth bound so we want to minimise the number of bytes loaded and stored per operation', ' Doing\\nthis approximately halves the time taken to run the function for all image sizes', '\\n\\n1\\n\\n\\x0cThe ﬂoating point operation, division, takes far more clock cycles to compute than multiplication\\nbecause the Intel compiler used divides by ﬁrst ﬁnding the reciprocal of the denominator and then\\nmultiplying it', ' This is why replacing all division operations with multiplication reduces the time taken\\nto run the function by a factor of 20', '\\n\\n3 Storing variables\\n\\nAware that memory bandwidth is often the bottleneck for programs, I originally approached the task\\nwith the attitude that no variables should be stored and all repeated values should be recomputed', '\\nAfter some trial and error, this was the slowest approach', ' Recomputing multiplications turned out to\\nbe slightly slower than retrieving data from a low-level cache', ' It was fastest, albeit only just, to take a\\nmixed approach with values that were computed with multiplication and that were used several times\\nstored as variables with simple, less used, values recalculated every time', '\\n\\n4 Compilers\\n\\nMy ﬁnal program is compiled using the command: ”icc -O3 -xHOST -std=c99 -Wall stencil', 'c -o stencil”', '\\nI chose to use the icc compiler because of its automatic vectorisation which enabled all the speed\\nincreases mentioned in the ﬁrst section', ' As can be seen below in Graph 1c, the gcc compiler performs\\nsimilarly to using the icc compiler with the -O1 ﬂag', ' This is because vectorisation is disabled with\\nthe -O1 ﬂag', ' The -O3 ﬂag performs best because it is designed for loop-heavy programs that operate\\non large datasets', ' xHost marginally increases the eﬃciency of the program by telling the compiler to\\ngenerate the highest level instruction set available on the compilation host processor', '\\n\\nVectorised\\nFactorised\\n\\nLoops switched\\n’restrict’ removed\\n\\n50\\n\\n40\\n\\n30\\n\\n20\\n\\n10\\n\\n0\\n\\nt\\n\\n0\\n\\n2,000\\n\\n4,000\\nn\\n\\n6,000\\n\\n8,000\\n\\n(a) Eﬃciency using varying\\nlevels of vectorisation\\n\\nEvaluation\\n\\n150\\n\\n100\\n\\nt\\n\\n50\\n\\n0\\n\\n0\\n\\nFloats\\nDoubles\\nDivision\\n\\n-O3\\n-O2\\n-O1\\n\\nWithout xHost\\n\\ngcc compiler\\n\\nt\\n\\n25\\n\\n20\\n\\n15\\n\\n10\\n\\n5\\n\\n0\\n\\n2,000\\n\\n4,000\\n\\n6,000\\n\\n8,000\\n\\n0\\n\\n2,000\\n\\n4,000\\n\\n6,000\\n\\n8,000\\n\\nn\\n\\nn\\n\\nt\\n\\n8', '6\\n\\n8', '55\\n\\n8', '5\\n\\n8', '45\\n\\n8', '4\\n\\n8', '35\\n\\nMixed\\n\\nNo variables\\nAll variables\\n\\n7,8607,8807,9007,9207,9407,9607,9808,000\\n\\nn\\n\\n(b) Eﬃciency of diﬀerent\\ndata types\\n\\n(c) Eﬃciency of diﬀerent\\ncompilers\\n\\n(d) Eﬃciency of using vari-\\nables against recomputing\\n\\nFigure 1: Results of diﬀerent optimisations\\n\\nAnalysing for an 8000x8000 image, I found that the program performed 1', '162GF LOP S in 8', '372s', ' This\\ngives it a performance of 0', '139GF LOP S/s', ' Meanwhile, with 3', '10 × 109bytes read and written, this\\ngives an operational intensity of 0', '374F LOP S/byte This puts the model some way oﬀ the roof of Blue\\nCrystal’s peak DRAM bandwidth', ' The function would have to be 32 times faster at that operational\\nintensity to hit Blue Crystal’s peak DRAM bandwidth', '\\n\\nThis raises the question of how could the program be made faster to reach that peak performance', '\\nA proﬁler shows that 85% of time spent in the program is within the inner loop', ' Therefore, it would be\\nmost appropriate to look to make improvements here', ' Since it is a loop, it would be best to optimise\\nfurther for vectorisation, possibly using techniques such as data alignment', ' It can also be seen from\\nvectorisation reports that the other two loops do not vectorise because of supposed data dependencies\\nbut this is less pressing because there are far fewer iterations of these loops so not much time is spent\\non them', '\\n\\n2\\n\\n\\x0c']\n"
     ]
    }
   ],
   "source": [
    "sentences = text.split('.')\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Serial Optimisations Report\\nIntroduction to High Performance Computing (COMS30005)', 'Oliver Ryan-George (or16131)\\n26/10/2018', 'Introduction', 'This report is a discussion of the optimisation of the function stencil in the given program stencil.c.\\nI will begin by presenting the speeds of the fastest optimisation and then continue by explaining how\\ndiﬀerent optimisations aﬀect the speed and why. I will then ﬁnish by reﬂecting on how fast the ﬁnal\\nprogram could have been and what could be done to further optimise it.', 'Results', 'The results for the ﬁnal program submitted on SAFE were taken as an average of ﬁve runs and are\\npresented below in Table 1. The eﬀects of diﬀerent alterations to the ﬁnal code are shown in Figure 1\\nand are referenced throughout.', 'Image Size\\n1024x1024\\n4096x4096\\n8000x8000', 'Table 1: Results', 'Initial runtime (s) Final runtime (s)', '8.153425\\n313.894160\\n611.285008', '0.088110\\n2.463002\\n8.371530', '1 Vectorisation', 'The most impactful changes on the eﬃciency of the function involved optimising it for vectorisation.\\nVectorisation is where the compiler parallelises code by performing an operation, lying within a for\\nloop, on a vector containing several elements of a subject array simultaneously. This is as opposed to\\nperforming the operation on sequentially on each element of the array.', 'In order for the compiler to vectorise code eﬀectively, for loops and data accesses need to take\\na certain form. One important rule is to make sure that array elements are accessed incrementally\\naccording to their index. This is so the compiler can put elements positioned next to each other in\\nmemory in vectors. This was not the case in the original code as the variable i was on the inside of\\na nested loop which was being multiplied in the index of arrays. By changing the loops in the ﬁnal\\nprogram we see a decrease in the time taken by a factor of 11 for an 8000x8000 image.', 'Another rule is to make sure it is clear to the compiler that there will be no pointer aliasing in\\nthe program using the restrict keyword. Without it, the vectorisation report states that there is an\\nassumed dependence between arrays. Putting restrict in sees a decrease in the time taken by a factor\\nof 5 for an 8000x8000 image.', 'A third rule is to make sure operations are separated to make it simple for the compiler to perform\\nthem. This is a compromise since I initially hypothesised that it would be faster to do all the operations\\nat once so the subject array element would only have to be loaded and stored once. This ended up\\nmattering little, probably since the cost of going to a low-level cache is very small. It would also have\\nthe beneﬁt of allowing factorisation so less costly multiplication would need to be done. The beneﬁts\\nof vectorisation outweigh this, however, as the vectorised version is marginally faster.', '2 Data types', 'The choice of data type has a signiﬁcant impact on the eﬃciency of the program. The original code\\nused doubles, each consisting of eight bytes which is unnecessarily precise for the task being performed.\\nFloats consist of four bytes each and are suﬃcient to pass the test. Changing from doubles to ﬂoats\\ndoubles the operational intensity of the function which is especially beneﬁcial as the program is memory\\nbandwidth bound so we want to minimise the number of bytes loaded and stored per operation. Doing\\nthis approximately halves the time taken to run the function for all image sizes.', '1', '\\x0cThe ﬂoating point operation, division, takes far more clock cycles to compute than multiplication\\nbecause the Intel compiler used divides by ﬁrst ﬁnding the reciprocal of the denominator and then\\nmultiplying it. This is why replacing all division operations with multiplication reduces the time taken\\nto run the function by a factor of 20.', '3 Storing variables', 'Aware that memory bandwidth is often the bottleneck for programs, I originally approached the task\\nwith the attitude that no variables should be stored and all repeated values should be recomputed.\\nAfter some trial and error, this was the slowest approach. Recomputing multiplications turned out to\\nbe slightly slower than retrieving data from a low-level cache. It was fastest, albeit only just, to take a\\nmixed approach with values that were computed with multiplication and that were used several times\\nstored as variables with simple, less used, values recalculated every time.', '4 Compilers', 'My ﬁnal program is compiled using the command: ”icc -O3 -xHOST -std=c99 -Wall stencil.c -o stencil”.\\nI chose to use the icc compiler because of its automatic vectorisation which enabled all the speed\\nincreases mentioned in the ﬁrst section. As can be seen below in Graph 1c, the gcc compiler performs\\nsimilarly to using the icc compiler with the -O1 ﬂag. This is because vectorisation is disabled with\\nthe -O1 ﬂag. The -O3 ﬂag performs best because it is designed for loop-heavy programs that operate\\non large datasets. xHost marginally increases the eﬃciency of the program by telling the compiler to\\ngenerate the highest level instruction set available on the compilation host processor.', 'Vectorised\\nFactorised', 'Loops switched\\n’restrict’ removed', '50', '40', '30', '20', '10', '0', 't', '0', '2,000', '4,000\\nn', '6,000', '8,000', '(a) Eﬃciency using varying\\nlevels of vectorisation', 'Evaluation', '150', '100', 't', '50', '0', '0', 'Floats\\nDoubles\\nDivision', '-O3\\n-O2\\n-O1', 'Without xHost', 'gcc compiler', 't', '25', '20', '15', '10', '5', '0', '2,000', '4,000', '6,000', '8,000', '0', '2,000', '4,000', '6,000', '8,000', 'n', 'n', 't', '8.6', '8.55', '8.5', '8.45', '8.4', '8.35', 'Mixed', 'No variables\\nAll variables', '7,8607,8807,9007,9207,9407,9607,9808,000', 'n', '(b) Eﬃciency of diﬀerent\\ndata types', '(c) Eﬃciency of diﬀerent\\ncompilers', '(d) Eﬃciency of using vari-\\nables against recomputing', 'Figure 1: Results of diﬀerent optimisations', 'Analysing for an 8000x8000 image, I found that the program performed 1.162GF LOP S in 8.372s. This\\ngives it a performance of 0.139GF LOP S/s. Meanwhile, with 3.10 × 109bytes read and written, this\\ngives an operational intensity of 0.374F LOP S/byte This puts the model some way oﬀ the roof of Blue\\nCrystal’s peak DRAM bandwidth. The function would have to be 32 times faster at that operational\\nintensity to hit Blue Crystal’s peak DRAM bandwidth.', 'This raises the question of how could the program be made faster to reach that peak performance.\\nA proﬁler shows that 85% of time spent in the program is within the inner loop. Therefore, it would be\\nmost appropriate to look to make improvements here. Since it is a loop, it would be best to optimise\\nfurther for vectorisation, possibly using techniques such as data alignment. It can also be seen from\\nvectorisation reports that the other two loops do not vectorise because of supposed data dependencies\\nbut this is less pressing because there are far fewer iterations of these loops so not much time is spent\\non them.', '2', '\\x0c']\n"
     ]
    }
   ],
   "source": [
    "paragraphs = text.split('\\n\\n')\n",
    "for pg in paragraphs:\n",
    "    pg = pg.replace('\\n', ' ')\n",
    "print (paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
